{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datapreparation import *\n",
    "train_image,train_label, test_image, test_label, val_image, val_label=LRP_Penobscot(shape=(992,192), stridetrain=(128,64), strideval=(128,64), stridetest=(128,64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 02:37:16.695773: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-31 02:37:16.721329: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-31 02:37:16.721358: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-31 02:37:16.722414: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-31 02:37:16.728178: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-31 02:37:17.106542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.profiler.model_analyzer import profile\n",
    "from tensorflow.python.profiler.option_builder import ProfileOptionBuilder\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print('TensorFlow:', tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.attention import Attention_unet\n",
    "from models.unet import Unet\n",
    "from models.unet3plus import Unet_3plus\n",
    "from models.bridgenet import FlexibleBridgeNet\n",
    "from models.efficientNetB1 import EfficientNetB1\n",
    "from network.CFPNetM import CFPNetM\n",
    "from network.ENet import ENet\n",
    "from network.ESPNet import ESPNet\n",
    "from network.ICNet import ICNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' filters=[]\\nfor i in range(0,int(6)):\\n      filters.append(2**(4+i))\\nmodel = Unet_3plus(tam_entrada=(992, 192, 1), n_filters=filters, classes=6,kernel_size=11,dropout_rate=0) '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" filters=[]\n",
    "for i in range(0,int(6)):\n",
    "      filters.append(2**(4+i))\n",
    "model = Unet_3plus(tam_entrada=(992, 192, 1), n_filters=filters, classes=6,kernel_size=11,dropout_rate=0) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 02:37:54.197918: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-31 02:37:54.225869: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-31 02:37:54.228649: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-31 02:37:54.232152: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-31 02:37:54.234248: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-31 02:37:54.237044: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-31 02:37:54.475847: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-31 02:37:54.478349: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-31 02:37:54.481332: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-31 02:37:54.483656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 491 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:12:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# model=ICNet(992, 192, 1, 6)\n",
    "model = EfficientNetB1(992,192, 1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' import lwbna_unet as unet\\nmodel = unet.LWBNAUnet(\\n    n_classes=6, \\n    filters=64, \\n    depth=4, \\n    midblock_steps=4, \\n    dropout_rate=0.3, \\n    name=\"my_unet\"\\n)\\nmodel.build(input_shape=(16,992,192,1)) '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" import lwbna_unet as unet\n",
    "model = unet.LWBNAUnet(\n",
    "    n_classes=6, \n",
    "    filters=64, \n",
    "    depth=4, \n",
    "    midblock_steps=4, \n",
    "    dropout_rate=0.3, \n",
    "    name=\"my_unet\"\n",
    ")\n",
    "model.build(input_shape=(16,992,192,1)) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = FlexibleBridgeNet(input_size=(992, 192, 1),up_down_times=5, Y_channels=1, kernel_size=11,\n",
    "                              kernels_all=[16, 32, 64, 128, 256, 512], conv2act_repeat=2, res_case=0,\n",
    "                              res_number=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 992, 192, 1)]     0         \n",
      "                                                                 \n",
      " efficientnetb1 (Functional  (None, 31, 6, 1280)       6574659   \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 62, 12, 256)       2949376   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 124, 24, 128)      295040    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 248, 48, 64)       73792     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2D  (None, 496, 96, 32)       18464     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2D  (None, 992, 192, 6)       1734      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9913065 (37.82 MB)\n",
      "Trainable params: 9851014 (37.58 MB)\n",
      "Non-trainable params: 62051 (242.39 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nunes/miniconda3/envs/seismic_tf/lib/python3.9/site-packages/tensorflow/python/profiler/internal/flops_registry.py:140: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "Flops: 3,467,596,648\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/6.94b flops)\n",
      "  conv2d_transpose/conv2d_transpose (1.10b/1.10b flops)\n",
      "  conv2d_transpose_1/conv2d_transpose (438.83m/438.83m flops)\n",
      "  conv2d_transpose_2/conv2d_transpose (438.83m/438.83m flops)\n",
      "  conv2d_transpose_3/conv2d_transpose (438.83m/438.83m flops)\n",
      "  efficientnetb1/block7b_expand_conv/Conv2D (228.56m/228.56m flops)\n",
      "  efficientnetb1/block7b_project_conv/Conv2D (228.56m/228.56m flops)\n",
      "  conv2d_transpose_4/conv2d_transpose (164.56m/164.56m flops)\n",
      "  efficientnetb1/top_conv/Conv2D (152.37m/152.37m flops)\n",
      "  efficientnetb1/block2a_expand_conv/Conv2D (146.28m/146.28m flops)\n",
      "  efficientnetb1/block7a_project_conv/Conv2D (137.13m/137.13m flops)\n",
      "  efficientnetb1/block5b_expand_conv/Conv2D (111.99m/111.99m flops)\n",
      "  efficientnetb1/block5b_project_conv/Conv2D (111.99m/111.99m flops)\n",
      "  efficientnetb1/block5c_expand_conv/Conv2D (111.99m/111.99m flops)\n",
      "  efficientnetb1/block5c_project_conv/Conv2D (111.99m/111.99m flops)\n",
      "  efficientnetb1/block5d_expand_conv/Conv2D (111.99m/111.99m flops)\n",
      "  efficientnetb1/block5d_project_conv/Conv2D (111.99m/111.99m flops)\n",
      "  efficientnetb1/block6a_expand_conv/Conv2D (111.99m/111.99m flops)\n",
      "  efficientnetb1/block2b_expand_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block2b_project_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block2c_expand_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block2c_project_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block3a_expand_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block6b_expand_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block6b_project_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block6c_expand_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block6c_project_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block6d_expand_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block6d_project_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block6e_expand_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block6e_project_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block7a_expand_conv/Conv2D (82.28m/82.28m flops)\n",
      "  efficientnetb1/block5a_project_conv/Conv2D (79.99m/79.99m flops)\n",
      "  efficientnetb1/block3b_expand_conv/Conv2D (57.14m/57.14m flops)\n",
      "  efficientnetb1/block3b_project_conv/Conv2D (57.14m/57.14m flops)\n",
      "  efficientnetb1/block3c_expand_conv/Conv2D (57.14m/57.14m flops)\n",
      "  efficientnetb1/block3c_project_conv/Conv2D (57.14m/57.14m flops)\n",
      "  efficientnetb1/block4a_expand_conv/Conv2D (57.14m/57.14m flops)\n",
      "  efficientnetb1/block4b_expand_conv/Conv2D (57.14m/57.14m flops)\n",
      "  efficientnetb1/block4b_project_conv/Conv2D (57.14m/57.14m flops)\n",
      "  efficientnetb1/block4c_expand_conv/Conv2D (57.14m/57.14m flops)\n",
      "  efficientnetb1/block4c_project_conv/Conv2D (57.14m/57.14m flops)\n",
      "  efficientnetb1/block4d_expand_conv/Conv2D (57.14m/57.14m flops)\n",
      "  efficientnetb1/block4d_project_conv/Conv2D (57.14m/57.14m flops)\n",
      "  efficientnetb1/block5a_expand_conv/Conv2D (57.14m/57.14m flops)\n",
      "  efficientnetb1/block2a_project_conv/Conv2D (54.85m/54.85m flops)\n",
      "  efficientnetb1/block1a_project_conv/Conv2D (48.76m/48.76m flops)\n",
      "  efficientnetb1/block6a_project_conv/Conv2D (48.00m/48.00m flops)\n",
      "  efficientnetb1/block3b_dwconv/depthwise (35.71m/35.71m flops)\n",
      "  efficientnetb1/block3c_dwconv/depthwise (35.71m/35.71m flops)\n",
      "  efficientnetb1/block3a_project_conv/Conv2D (34.28m/34.28m flops)\n",
      "  efficientnetb1/block2b_dwconv/depthwise (30.86m/30.86m flops)\n",
      "  efficientnetb1/block2c_dwconv/depthwise (30.86m/30.86m flops)\n",
      "  efficientnetb1/block4a_project_conv/Conv2D (28.57m/28.57m flops)\n",
      "  efficientnetb1/block1a_dwconv/depthwise (27.43m/27.43m flops)\n",
      "  efficientnetb1/stem_conv/Conv2D (27.43m/27.43m flops)\n",
      "  efficientnetb1/block5b_dwconv/depthwise (25.00m/25.00m flops)\n",
      "  efficientnetb1/block5c_dwconv/depthwise (25.00m/25.00m flops)\n",
      "  efficientnetb1/block5d_dwconv/depthwise (25.00m/25.00m flops)\n",
      "  efficientnetb1/block1b_project_conv/Conv2D (24.38m/24.38m flops)\n",
      "  efficientnetb1/block3a_dwconv/depthwise (21.43m/21.43m flops)\n",
      "  efficientnetb1/block2a_dwconv/depthwise (20.57m/20.57m flops)\n",
      "  efficientnetb1/block5a_dwconv/depthwise (17.86m/17.86m flops)\n",
      "  efficientnetb1/block1b_dwconv/depthwise (13.71m/13.71m flops)\n",
      "  efficientnetb1/block6b_dwconv/depthwise (10.71m/10.71m flops)\n",
      "  efficientnetb1/block6c_dwconv/depthwise (10.71m/10.71m flops)\n",
      "  efficientnetb1/block6d_dwconv/depthwise (10.71m/10.71m flops)\n",
      "  efficientnetb1/block6e_dwconv/depthwise (10.71m/10.71m flops)\n",
      "  efficientnetb1/block4b_dwconv/depthwise (6.43m/6.43m flops)\n",
      "  efficientnetb1/block4c_dwconv/depthwise (6.43m/6.43m flops)\n",
      "  efficientnetb1/block4d_dwconv/depthwise (6.43m/6.43m flops)\n",
      "  efficientnetb1/block7b_dwconv/depthwise (6.43m/6.43m flops)\n",
      "  efficientnetb1/block6a_dwconv/depthwise (6.25m/6.25m flops)\n",
      "  conv2d_transpose_4/Softmax (5.71m/5.71m flops)\n",
      "  efficientnetb1/block2a_expand_activation/mul (4.57m/4.57m flops)\n",
      "  efficientnetb1/block2a_expand_activation/mul_1 (4.57m/4.57m flops)\n",
      "  efficientnetb1/block7a_dwconv/depthwise (3.86m/3.86m flops)\n",
      "  efficientnetb1/block4a_dwconv/depthwise (3.21m/3.21m flops)\n",
      "  efficientnetb1/block2b_activation/mul (1.71m/1.71m flops)\n",
      "  efficientnetb1/block2b_activation/mul_1 (1.71m/1.71m flops)\n",
      "  efficientnetb1/block2b_expand_activation/mul (1.71m/1.71m flops)\n",
      "  efficientnetb1/block2b_expand_activation/mul_1 (1.71m/1.71m flops)\n",
      "  efficientnetb1/block2b_se_excite/mul (1.71m/1.71m flops)\n",
      "  efficientnetb1/block2b_se_squeeze/Mean (1.71m/1.71m flops)\n",
      "  efficientnetb1/block2c_activation/mul (1.71m/1.71m flops)\n",
      "  efficientnetb1/block2c_activation/mul_1 (1.71m/1.71m flops)\n",
      "  efficientnetb1/block2c_expand_activation/mul (1.71m/1.71m flops)\n",
      "  efficientnetb1/block2c_expand_activation/mul_1 (1.71m/1.71m flops)\n",
      "  efficientnetb1/block2c_se_excite/mul (1.71m/1.71m flops)\n",
      "  efficientnetb1/block2c_se_squeeze/Mean (1.71m/1.71m flops)\n",
      "  efficientnetb1/block3a_expand_activation/mul (1.71m/1.71m flops)\n",
      "  efficientnetb1/block3a_expand_activation/mul_1 (1.71m/1.71m flops)\n",
      "  conv2d_transpose_3/BiasAdd (1.52m/1.52m flops)\n",
      "  efficientnetb1/block1a_activation/mul (1.52m/1.52m flops)\n",
      "  efficientnetb1/block1a_activation/mul_1 (1.52m/1.52m flops)\n",
      "  efficientnetb1/block1a_se_excite/mul (1.52m/1.52m flops)\n",
      "  efficientnetb1/block1a_se_squeeze/Mean (1.52m/1.52m flops)\n",
      "  efficientnetb1/stem_activation/mul (1.52m/1.52m flops)\n",
      "  efficientnetb1/stem_activation/mul_1 (1.52m/1.52m flops)\n",
      "  conv2d_transpose_4/BiasAdd (1.14m/1.14m flops)\n",
      "  efficientnetb1/block2a_activation/mul (1.14m/1.14m flops)\n",
      "  efficientnetb1/block2a_activation/mul_1 (1.14m/1.14m flops)\n",
      "  efficientnetb1/block2a_se_excite/mul (1.14m/1.14m flops)\n",
      "  efficientnetb1/block2a_se_squeeze/Mean (1.14m/1.14m flops)\n",
      "  conv2d_transpose_2/BiasAdd (761.86k/761.86k flops)\n",
      "  efficientnetb1/block1b_activation/mul (761.86k/761.86k flops)\n",
      "  efficientnetb1/block1b_activation/mul_1 (761.86k/761.86k flops)\n",
      "  efficientnetb1/block1b_add/add (761.86k/761.86k flops)\n",
      "  efficientnetb1/block1b_se_excite/mul (761.86k/761.86k flops)\n",
      "  efficientnetb1/block1b_se_squeeze/Mean (761.86k/761.86k flops)\n",
      "  efficientnetb1/block3b_activation/mul (714.24k/714.24k flops)\n",
      "  efficientnetb1/block3b_activation/mul_1 (714.24k/714.24k flops)\n",
      "  efficientnetb1/block3b_expand_activation/mul (714.24k/714.24k flops)\n",
      "  efficientnetb1/block3b_expand_activation/mul_1 (714.24k/714.24k flops)\n",
      "  efficientnetb1/block3b_se_excite/mul (714.24k/714.24k flops)\n",
      "  efficientnetb1/block3b_se_squeeze/Mean (714.24k/714.24k flops)\n",
      "  efficientnetb1/block3c_activation/mul (714.24k/714.24k flops)\n",
      "  efficientnetb1/block3c_activation/mul_1 (714.24k/714.24k flops)\n",
      "  efficientnetb1/block3c_expand_activation/mul (714.24k/714.24k flops)\n",
      "  efficientnetb1/block3c_expand_activation/mul_1 (714.24k/714.24k flops)\n",
      "  efficientnetb1/block3c_se_excite/mul (714.24k/714.24k flops)\n",
      "  efficientnetb1/block3c_se_squeeze/Mean (714.24k/714.24k flops)\n",
      "  efficientnetb1/block4a_expand_activation/mul (714.24k/714.24k flops)\n",
      "  efficientnetb1/block4a_expand_activation/mul_1 (714.24k/714.24k flops)\n",
      "  efficientnetb1/block5b_activation/mul (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5b_activation/mul_1 (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5b_expand_activation/mul (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5b_expand_activation/mul_1 (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5b_se_excite/mul (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5b_se_squeeze/Mean (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5c_activation/mul (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5c_activation/mul_1 (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5c_expand_activation/mul (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5c_expand_activation/mul_1 (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5c_se_excite/mul (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5c_se_squeeze/Mean (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5d_activation/mul (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5d_activation/mul_1 (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5d_expand_activation/mul (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5d_expand_activation/mul_1 (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5d_se_excite/mul (499.97k/499.97k flops)\n",
      "  efficientnetb1/block5d_se_squeeze/Mean (499.97k/499.97k flops)\n",
      "  efficientnetb1/block6a_expand_activation/mul (499.97k/499.97k flops)\n",
      "  efficientnetb1/block6a_expand_activation/mul_1 (499.97k/499.97k flops)\n",
      "  efficientnetb1/block3a_activation/mul (428.54k/428.54k flops)\n",
      "  efficientnetb1/block3a_activation/mul_1 (428.54k/428.54k flops)\n",
      "  efficientnetb1/block3a_se_excite/mul (428.54k/428.54k flops)\n",
      "  efficientnetb1/block3a_se_squeeze/Mean (428.54k/428.54k flops)\n",
      "  conv2d_transpose_1/BiasAdd (380.93k/380.93k flops)\n",
      "  efficientnetb1/block4b_activation/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4b_activation/mul_1 (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4b_expand_activation/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4b_expand_activation/mul_1 (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4b_se_excite/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4b_se_squeeze/Mean (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4c_activation/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4c_activation/mul_1 (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4c_expand_activation/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4c_expand_activation/mul_1 (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4c_se_excite/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4c_se_squeeze/Mean (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4d_activation/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4d_activation/mul_1 (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4d_expand_activation/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4d_expand_activation/mul_1 (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4d_se_excite/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block4d_se_squeeze/Mean (357.12k/357.12k flops)\n",
      "  efficientnetb1/block5a_activation/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block5a_activation/mul_1 (357.12k/357.12k flops)\n",
      "  efficientnetb1/block5a_expand_activation/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block5a_expand_activation/mul_1 (357.12k/357.12k flops)\n",
      "  efficientnetb1/block5a_se_excite/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block5a_se_squeeze/Mean (357.12k/357.12k flops)\n",
      "  efficientnetb1/block7b_activation/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block7b_activation/mul_1 (357.12k/357.12k flops)\n",
      "  efficientnetb1/block7b_expand_activation/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block7b_expand_activation/mul_1 (357.12k/357.12k flops)\n",
      "  efficientnetb1/block7b_se_excite/mul (357.12k/357.12k flops)\n",
      "  efficientnetb1/block7b_se_squeeze/Mean (357.12k/357.12k flops)\n",
      "  efficientnetb1/block7b_se_expand/Conv2D (307.20k/307.20k flops)\n",
      "  efficientnetb1/block7b_se_reduce/Conv2D (307.20k/307.20k flops)\n",
      "  efficientnetb1/block2b_add/add (285.70k/285.70k flops)\n",
      "  efficientnetb1/block2c_add/add (285.70k/285.70k flops)\n",
      "  efficientnetb1/top_activation/mul (238.08k/238.08k flops)\n",
      "  efficientnetb1/top_activation/mul_1 (238.08k/238.08k flops)\n",
      "  efficientnetb1/block6b_activation/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6b_activation/mul_1 (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6b_expand_activation/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6b_expand_activation/mul_1 (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6b_se_excite/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6b_se_squeeze/Mean (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6c_activation/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6c_activation/mul_1 (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6c_expand_activation/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6c_expand_activation/mul_1 (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6c_se_excite/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6c_se_squeeze/Mean (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6d_activation/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6d_activation/mul_1 (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6d_expand_activation/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6d_expand_activation/mul_1 (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6d_se_excite/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6d_se_squeeze/Mean (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6e_activation/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6e_activation/mul_1 (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6e_expand_activation/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6e_expand_activation/mul_1 (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6e_se_excite/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block6e_se_squeeze/Mean (214.27k/214.27k flops)\n",
      "  efficientnetb1/block7a_activation/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block7a_activation/mul_1 (214.27k/214.27k flops)\n",
      "  efficientnetb1/block7a_expand_activation/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block7a_expand_activation/mul_1 (214.27k/214.27k flops)\n",
      "  efficientnetb1/block7a_se_excite/mul (214.27k/214.27k flops)\n",
      "  efficientnetb1/block7a_se_squeeze/Mean (214.27k/214.27k flops)\n",
      "  conv2d_transpose/BiasAdd (190.46k/190.46k flops)\n",
      "  efficientnetb1/normalization/sub (190.46k/190.46k flops)\n",
      "  efficientnetb1/normalization/truediv (190.46k/190.46k flops)\n",
      "  efficientnetb1/rescaling/add (190.46k/190.46k flops)\n",
      "  efficientnetb1/rescaling/mul (190.46k/190.46k flops)\n",
      "  efficientnetb1/block4a_activation/mul (178.56k/178.56k flops)\n",
      "  efficientnetb1/block4a_activation/mul_1 (178.56k/178.56k flops)\n",
      "  efficientnetb1/block4a_se_excite/mul (178.56k/178.56k flops)\n",
      "  efficientnetb1/block4a_se_squeeze/Mean (178.56k/178.56k flops)\n",
      "  efficientnetb1/block6a_activation/mul (124.99k/124.99k flops)\n",
      "  efficientnetb1/block6a_activation/mul_1 (124.99k/124.99k flops)\n",
      "  efficientnetb1/block6a_se_excite/mul (124.99k/124.99k flops)\n",
      "  efficientnetb1/block6a_se_squeeze/Mean (124.99k/124.99k flops)\n",
      "  efficientnetb1/block3b_add/add (119.04k/119.04k flops)\n",
      "  efficientnetb1/block3c_add/add (119.04k/119.04k flops)\n",
      "  efficientnetb1/block6b_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  efficientnetb1/block6b_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  efficientnetb1/block6c_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  efficientnetb1/block6c_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  efficientnetb1/block6d_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  efficientnetb1/block6d_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  efficientnetb1/block6e_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  efficientnetb1/block6e_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  efficientnetb1/block7a_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  efficientnetb1/block7a_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  efficientnetb1/block5b_add/add (83.33k/83.33k flops)\n",
      "  efficientnetb1/block5c_add/add (83.33k/83.33k flops)\n",
      "  efficientnetb1/block5d_add/add (83.33k/83.33k flops)\n",
      "  efficientnetb1/block4b_add/add (59.52k/59.52k flops)\n",
      "  efficientnetb1/block4c_add/add (59.52k/59.52k flops)\n",
      "  efficientnetb1/block4d_add/add (59.52k/59.52k flops)\n",
      "  efficientnetb1/block7b_add/add (59.52k/59.52k flops)\n",
      "  efficientnetb1/block5b_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  efficientnetb1/block5b_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  efficientnetb1/block5c_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  efficientnetb1/block5c_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  efficientnetb1/block5d_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  efficientnetb1/block5d_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  efficientnetb1/block6a_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  efficientnetb1/block6a_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  efficientnetb1/block6b_add/add (35.71k/35.71k flops)\n",
      "  efficientnetb1/block6c_add/add (35.71k/35.71k flops)\n",
      "  efficientnetb1/block6d_add/add (35.71k/35.71k flops)\n",
      "  efficientnetb1/block6e_add/add (35.71k/35.71k flops)\n",
      "  efficientnetb1/block4b_se_expand/Conv2D (19.20k/19.20k flops)\n",
      "  efficientnetb1/block4b_se_reduce/Conv2D (19.20k/19.20k flops)\n",
      "  efficientnetb1/block4c_se_expand/Conv2D (19.20k/19.20k flops)\n",
      "  efficientnetb1/block4c_se_reduce/Conv2D (19.20k/19.20k flops)\n",
      "  efficientnetb1/block4d_se_expand/Conv2D (19.20k/19.20k flops)\n",
      "  efficientnetb1/block4d_se_reduce/Conv2D (19.20k/19.20k flops)\n",
      "  efficientnetb1/block5a_se_expand/Conv2D (19.20k/19.20k flops)\n",
      "  efficientnetb1/block5a_se_reduce/Conv2D (19.20k/19.20k flops)\n",
      "  efficientnetb1/block3b_se_expand/Conv2D (4.80k/4.80k flops)\n",
      "  efficientnetb1/block3b_se_reduce/Conv2D (4.80k/4.80k flops)\n",
      "  efficientnetb1/block3c_se_expand/Conv2D (4.80k/4.80k flops)\n",
      "  efficientnetb1/block3c_se_reduce/Conv2D (4.80k/4.80k flops)\n",
      "  efficientnetb1/block4a_se_expand/Conv2D (4.80k/4.80k flops)\n",
      "  efficientnetb1/block4a_se_reduce/Conv2D (4.80k/4.80k flops)\n",
      "  efficientnetb1/block7b_se_expand/BiasAdd (1.92k/1.92k flops)\n",
      "  efficientnetb1/block2b_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  efficientnetb1/block2b_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  efficientnetb1/block2c_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  efficientnetb1/block2c_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  efficientnetb1/block3a_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  efficientnetb1/block3a_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  efficientnetb1/block6b_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  efficientnetb1/block6c_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  efficientnetb1/block6d_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  efficientnetb1/block6e_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  efficientnetb1/block7a_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  efficientnetb1/block2a_se_expand/Conv2D (768/768 flops)\n",
      "  efficientnetb1/block2a_se_reduce/Conv2D (768/768 flops)\n",
      "  efficientnetb1/block5b_se_expand/BiasAdd (672/672 flops)\n",
      "  efficientnetb1/block5c_se_expand/BiasAdd (672/672 flops)\n",
      "  efficientnetb1/block5d_se_expand/BiasAdd (672/672 flops)\n",
      "  efficientnetb1/block6a_se_expand/BiasAdd (672/672 flops)\n",
      "  efficientnetb1/block1a_se_expand/Conv2D (512/512 flops)\n",
      "  efficientnetb1/block1a_se_reduce/Conv2D (512/512 flops)\n",
      "  efficientnetb1/block4b_se_expand/BiasAdd (480/480 flops)\n",
      "  efficientnetb1/block4c_se_expand/BiasAdd (480/480 flops)\n",
      "  efficientnetb1/block4d_se_expand/BiasAdd (480/480 flops)\n",
      "  efficientnetb1/block5a_se_expand/BiasAdd (480/480 flops)\n",
      "  efficientnetb1/block3b_se_expand/BiasAdd (240/240 flops)\n",
      "  efficientnetb1/block3c_se_expand/BiasAdd (240/240 flops)\n",
      "  efficientnetb1/block4a_se_expand/BiasAdd (240/240 flops)\n",
      "  efficientnetb1/block2b_se_expand/BiasAdd (144/144 flops)\n",
      "  efficientnetb1/block2c_se_expand/BiasAdd (144/144 flops)\n",
      "  efficientnetb1/block3a_se_expand/BiasAdd (144/144 flops)\n",
      "  efficientnetb1/block1b_se_expand/Conv2D (128/128 flops)\n",
      "  efficientnetb1/block1b_se_reduce/Conv2D (128/128 flops)\n",
      "  efficientnetb1/block2a_se_expand/BiasAdd (96/96 flops)\n",
      "  efficientnetb1/block7b_se_reduce/BiasAdd (80/80 flops)\n",
      "  efficientnetb1/block7b_se_reduce/mul (80/80 flops)\n",
      "  efficientnetb1/block7b_se_reduce/mul_1 (80/80 flops)\n",
      "  efficientnetb1/block6b_se_reduce/BiasAdd (48/48 flops)\n",
      "  efficientnetb1/block6b_se_reduce/mul (48/48 flops)\n",
      "  efficientnetb1/block6b_se_reduce/mul_1 (48/48 flops)\n",
      "  efficientnetb1/block6c_se_reduce/BiasAdd (48/48 flops)\n",
      "  efficientnetb1/block6c_se_reduce/mul (48/48 flops)\n",
      "  efficientnetb1/block6c_se_reduce/mul_1 (48/48 flops)\n",
      "  efficientnetb1/block6d_se_reduce/BiasAdd (48/48 flops)\n",
      "  efficientnetb1/block6d_se_reduce/mul (48/48 flops)\n",
      "  efficientnetb1/block6d_se_reduce/mul_1 (48/48 flops)\n",
      "  efficientnetb1/block6e_se_reduce/BiasAdd (48/48 flops)\n",
      "  efficientnetb1/block6e_se_reduce/mul (48/48 flops)\n",
      "  efficientnetb1/block6e_se_reduce/mul_1 (48/48 flops)\n",
      "  efficientnetb1/block7a_se_reduce/BiasAdd (48/48 flops)\n",
      "  efficientnetb1/block7a_se_reduce/mul (48/48 flops)\n",
      "  efficientnetb1/block7a_se_reduce/mul_1 (48/48 flops)\n",
      "  efficientnetb1/block1a_se_expand/BiasAdd (32/32 flops)\n",
      "  efficientnetb1/block5b_se_reduce/BiasAdd (28/28 flops)\n",
      "  efficientnetb1/block5b_se_reduce/mul (28/28 flops)\n",
      "  efficientnetb1/block5b_se_reduce/mul_1 (28/28 flops)\n",
      "  efficientnetb1/block5c_se_reduce/BiasAdd (28/28 flops)\n",
      "  efficientnetb1/block5c_se_reduce/mul (28/28 flops)\n",
      "  efficientnetb1/block5c_se_reduce/mul_1 (28/28 flops)\n",
      "  efficientnetb1/block5d_se_reduce/BiasAdd (28/28 flops)\n",
      "  efficientnetb1/block5d_se_reduce/mul (28/28 flops)\n",
      "  efficientnetb1/block5d_se_reduce/mul_1 (28/28 flops)\n",
      "  efficientnetb1/block6a_se_reduce/BiasAdd (28/28 flops)\n",
      "  efficientnetb1/block6a_se_reduce/mul (28/28 flops)\n",
      "  efficientnetb1/block6a_se_reduce/mul_1 (28/28 flops)\n",
      "  efficientnetb1/block4b_se_reduce/BiasAdd (20/20 flops)\n",
      "  efficientnetb1/block4b_se_reduce/mul (20/20 flops)\n",
      "  efficientnetb1/block4b_se_reduce/mul_1 (20/20 flops)\n",
      "  efficientnetb1/block4c_se_reduce/BiasAdd (20/20 flops)\n",
      "  efficientnetb1/block4c_se_reduce/mul (20/20 flops)\n",
      "  efficientnetb1/block4c_se_reduce/mul_1 (20/20 flops)\n",
      "  efficientnetb1/block4d_se_reduce/BiasAdd (20/20 flops)\n",
      "  efficientnetb1/block4d_se_reduce/mul (20/20 flops)\n",
      "  efficientnetb1/block4d_se_reduce/mul_1 (20/20 flops)\n",
      "  efficientnetb1/block5a_se_reduce/BiasAdd (20/20 flops)\n",
      "  efficientnetb1/block5a_se_reduce/mul (20/20 flops)\n",
      "  efficientnetb1/block5a_se_reduce/mul_1 (20/20 flops)\n",
      "  efficientnetb1/block1b_se_expand/BiasAdd (16/16 flops)\n",
      "  efficientnetb1/block3b_se_reduce/BiasAdd (10/10 flops)\n",
      "  efficientnetb1/block3b_se_reduce/mul (10/10 flops)\n",
      "  efficientnetb1/block3b_se_reduce/mul_1 (10/10 flops)\n",
      "  efficientnetb1/block3c_se_reduce/BiasAdd (10/10 flops)\n",
      "  efficientnetb1/block3c_se_reduce/mul (10/10 flops)\n",
      "  efficientnetb1/block3c_se_reduce/mul_1 (10/10 flops)\n",
      "  efficientnetb1/block4a_se_reduce/BiasAdd (10/10 flops)\n",
      "  efficientnetb1/block4a_se_reduce/mul (10/10 flops)\n",
      "  efficientnetb1/block4a_se_reduce/mul_1 (10/10 flops)\n",
      "  efficientnetb1/block1a_se_reduce/BiasAdd (8/8 flops)\n",
      "  efficientnetb1/block1a_se_reduce/mul (8/8 flops)\n",
      "  efficientnetb1/block1a_se_reduce/mul_1 (8/8 flops)\n",
      "  efficientnetb1/block2b_se_reduce/BiasAdd (6/6 flops)\n",
      "  efficientnetb1/block2b_se_reduce/mul (6/6 flops)\n",
      "  efficientnetb1/block2b_se_reduce/mul_1 (6/6 flops)\n",
      "  efficientnetb1/block2c_se_reduce/BiasAdd (6/6 flops)\n",
      "  efficientnetb1/block2c_se_reduce/mul (6/6 flops)\n",
      "  efficientnetb1/block2c_se_reduce/mul_1 (6/6 flops)\n",
      "  efficientnetb1/block3a_se_reduce/BiasAdd (6/6 flops)\n",
      "  efficientnetb1/block3a_se_reduce/mul (6/6 flops)\n",
      "  efficientnetb1/block3a_se_reduce/mul_1 (6/6 flops)\n",
      "  efficientnetb1/block1b_se_reduce/BiasAdd (4/4 flops)\n",
      "  efficientnetb1/block1b_se_reduce/mul (4/4 flops)\n",
      "  efficientnetb1/block1b_se_reduce/mul_1 (4/4 flops)\n",
      "  efficientnetb1/block2a_se_reduce/BiasAdd (4/4 flops)\n",
      "  efficientnetb1/block2a_se_reduce/mul (4/4 flops)\n",
      "  efficientnetb1/block2a_se_reduce/mul_1 (4/4 flops)\n",
      "  efficientnetb1/normalization/Maximum (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    }
   ],
   "source": [
    "#model = tf.keras.applications.ResNet50()\n",
    "\n",
    "forward_pass = tf.function(\n",
    "    model.call,\n",
    "    input_signature=[tf.TensorSpec(shape=(1,992,192,1))])\n",
    "\n",
    "graph_info = profile(forward_pass.get_concrete_function().graph,\n",
    "                        options=ProfileOptionBuilder.float_operation())\n",
    "# The //2 is necessary since `profile` counts multiply and accumulate\n",
    "# as two flops, here we report the total number of multiply accumulate ops\n",
    "flops = graph_info.total_float_ops // 2\n",
    "print('Flops: {:,}'.format(flops))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismic_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
