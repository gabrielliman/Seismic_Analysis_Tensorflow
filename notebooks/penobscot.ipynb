{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(folder_path, mask_path):\n",
    "\n",
    "    tiff_files = [file for file in os.listdir(folder_path) if file.endswith('.tiff')]\n",
    "\n",
    "    images = []\n",
    "    masks = []\n",
    "    for file in tiff_files:\n",
    "        image = Image.open(os.path.join(folder_path, file))\n",
    "        images.append(np.array(image))\n",
    "        mask = Image.open(os.path.join(mask_path, os.path.splitext(file)[0] + '_mask.png'))\n",
    "        masks.append(np.array(mask))\n",
    "\n",
    "    return np.array(images), np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_patches(images, patch_size, stride):\n",
    "    num_images, height, width = images.shape\n",
    "    \n",
    "    patches_per_dim_h = (height - patch_size) // stride + 1\n",
    "    patches_per_dim_w = (width - patch_size) // stride + 1\n",
    "    \n",
    "    num_patches_per_image = patches_per_dim_h * patches_per_dim_w\n",
    "    \n",
    "    patches = np.zeros((num_images * num_patches_per_image, patch_size, patch_size), dtype=images.dtype)\n",
    "    \n",
    "    idx = 0\n",
    "    for image in images:\n",
    "        for h in range(0, height - patch_size + 1, stride):\n",
    "            for w in range(0, width - patch_size + 1, stride):\n",
    "                patch = image[h:h+patch_size, w:w+patch_size]\n",
    "                patches[idx] = patch\n",
    "                idx += 1\n",
    "                \n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data, train_ratio=0.7, test_ratio=0.2, val_ratio=0.1):\n",
    "    num_samples = data.shape[0]\n",
    "    \n",
    "    train_size = int(train_ratio * num_samples)\n",
    "    val_size = int(val_ratio * num_samples)\n",
    "    \n",
    "    train_indices = np.arange(0, train_size)\n",
    "    val_indices = np.arange(train_size, train_size+val_size)\n",
    "    test_indices = np.arange(train_size+val_size, num_samples)\n",
    "    \n",
    "    train_set = data[train_indices]\n",
    "    test_set = data[test_indices]\n",
    "    val_set = data[val_indices]\n",
    "    \n",
    "    return train_set, test_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penobscot_data(patch,stride):\n",
    "    inlines, masks_in=read_files(\"/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/inlines\",'/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/masks')\n",
    "    crosslines, masks_cross=read_files(\"/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/crosslines\",'/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/masks')\n",
    "    patch_inline=divide_into_patches(inlines,patch,stride)\n",
    "    patch_crossline=divide_into_patches(crosslines,patch,stride)\n",
    "    patch_mask_in=divide_into_patches(masks_in,patch,stride)\n",
    "    patch_mask_cross=divide_into_patches(masks_cross,patch,stride)\n",
    "\n",
    "    in_train,in_test,in_val=data_split(patch_inline)\n",
    "    mask_in_train,mask_in_test,mask_in_val=data_split(patch_mask_in)\n",
    "    cross_train,cross_test,cross_val=data_split(patch_crossline)\n",
    "    mask_cross_train,mask_cross_test,mask_cross_val=data_split(patch_mask_cross)\n",
    "\n",
    "    trainX=np.append(in_train,cross_train, axis=0)\n",
    "    trainY=np.append(mask_in_train,mask_cross_train, axis=0)\n",
    "    testX=np.append(in_test,cross_test, axis=0)\n",
    "    testY=np.append(mask_in_test,mask_cross_test, axis=0)\n",
    "    valX=np.append(in_val,cross_val, axis=0)\n",
    "    valY=np.append(mask_in_val,mask_cross_val, axis=0)\n",
    "\n",
    "    return trainX, trainY, testX, testY, valX, valY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlines, masks_in=read_files(\"/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/inlines\",'/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/masks')\n",
    "inlines = ((inlines + 32767) / 65534) * 255\n",
    "inlines=inlines.astype(np.uint8)\n",
    "#crosslines, masks_cross=read_files(\"/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/crosslines\",'/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(inlines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crosslines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(inlines\u001b[38;5;241m.\u001b[39mshape,\u001b[43mcrosslines\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(masks_in\u001b[38;5;241m.\u001b[39mshape,masks_cross\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'crosslines' is not defined"
     ]
    }
   ],
   "source": [
    "print(inlines.shape,crosslines.shape)\n",
    "print(masks_in.shape,masks_cross.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_inline=divide_into_patches(inlines,50,30)\n",
    "patch_crossline=divide_into_patches(crosslines,50,30)\n",
    "patch_mask_in=divide_into_patches(masks_in,50,30)\n",
    "patch_mask_cross=divide_into_patches(masks_cross,50,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(438060, 50, 50) (447811, 50, 50)\n",
      "(438060, 50, 50) (447811, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "print(patch_inline.shape,patch_crossline.shape)\n",
    "print(patch_mask_in.shape,patch_mask_cross.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306642, 50, 50) (87612, 50, 50) (43806, 50, 50)\n",
      "(306642, 50, 50) (87612, 50, 50) (43806, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "in_train,in_test,in_val=data_split(patch_inline)\n",
    "print(in_train.shape, in_test.shape, in_val.shape)\n",
    "\n",
    "mask_in_train,mask_in_test,mask_in_val=data_split(patch_mask_in)\n",
    "print(mask_in_train.shape, mask_in_test.shape, mask_in_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313467, 50, 50) (89563, 50, 50) (44781, 50, 50)\n",
      "(313467, 50, 50) (89563, 50, 50) (44781, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "cross_train,cross_test,cross_val=data_split(patch_crossline)\n",
    "print(cross_train.shape, cross_test.shape, cross_val.shape)\n",
    "\n",
    "mask_cross_train,mask_cross_test,mask_cross_val=data_split(patch_mask_cross)\n",
    "print(mask_cross_train.shape, mask_cross_test.shape, mask_cross_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=np.append(in_train,cross_train, axis=0)\n",
    "trainY=np.append(mask_in_train,mask_cross_train, axis=0)\n",
    "testX=np.append(in_test,cross_test, axis=0)\n",
    "testY=np.append(mask_in_test,mask_cross_test, axis=0)\n",
    "valX=np.append(in_val,cross_val, axis=0)\n",
    "valY=np.append(mask_in_val,mask_cross_val, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620109, 50, 50)\n",
      "(620109, 50, 50)\n",
      "(177175, 50, 50)\n",
      "(177175, 50, 50)\n",
      "(88587, 50, 50)\n",
      "(88587, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)\n",
    "print(valX.shape)\n",
    "print(valY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def read_files(folder_path, mask_path):\n",
    "\n",
    "    tiff_files = [file for file in os.listdir(folder_path) if file.endswith('.tiff')]\n",
    "\n",
    "    images = []\n",
    "    masks = []\n",
    "    for file in tiff_files:\n",
    "        image = Image.open(os.path.join(folder_path, file))\n",
    "        images.append(np.array(image))\n",
    "        mask = Image.open(os.path.join(mask_path, os.path.splitext(file)[0] + '_mask.png'))\n",
    "        masks.append(np.array(mask))\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "\n",
    "def divide_into_patches(images, patch_size, stride):\n",
    "    num_images, height, width = images.shape\n",
    "    \n",
    "    patches_per_dim_h = (height - patch_size) // stride + 1\n",
    "    patches_per_dim_w = (width - patch_size) // stride + 1\n",
    "    \n",
    "    num_patches_per_image = patches_per_dim_h * patches_per_dim_w\n",
    "    \n",
    "    patches = np.zeros((num_images * num_patches_per_image, patch_size, patch_size), dtype=images.dtype)\n",
    "    \n",
    "    idx = 0\n",
    "    for image in images:\n",
    "        for h in range(0, height - patch_size + 1, stride):\n",
    "            for w in range(0, width - patch_size + 1, stride):\n",
    "                patch = image[h:h+patch_size, w:w+patch_size]\n",
    "                patches[idx] = patch\n",
    "                idx += 1\n",
    "                \n",
    "    return patches\n",
    "\n",
    "\n",
    "def data_split(data, train_ratio=0.7, test_ratio=0.2, val_ratio=0.1):\n",
    "    num_samples = data.shape[0]\n",
    "    \n",
    "    train_size = int(train_ratio * num_samples)\n",
    "    val_size = int(val_ratio * num_samples)\n",
    "    \n",
    "    train_indices = np.arange(0, train_size)\n",
    "    val_indices = np.arange(train_size, train_size+val_size)\n",
    "    test_indices = np.arange(train_size+val_size, num_samples)\n",
    "    \n",
    "    train_set = data[train_indices]\n",
    "    test_set = data[test_indices]\n",
    "    val_set = data[val_indices]\n",
    "    \n",
    "    return train_set, test_set, val_set\n",
    "\n",
    "\n",
    "def majority_class(images, masks, threshold_percentage=0.7):\n",
    "    n, a, b = masks.shape\n",
    "    majority_classes = []\n",
    "    majority_images=[]\n",
    "\n",
    "    for i in range(n):\n",
    "        sample = masks[i]\n",
    "        flattened_sample = sample.flatten()\n",
    "        unique_classes, counts = np.unique(flattened_sample, return_counts=True)\n",
    "        max_count = np.max(counts)\n",
    "        total_count = np.sum(counts)\n",
    "        if max_count / total_count >= threshold_percentage:\n",
    "            majority_class_index = np.argmax(counts)\n",
    "            majority_class = unique_classes[majority_class_index]\n",
    "            majority_classes.append(majority_class)\n",
    "            majority_images.append(images[i])\n",
    "\n",
    "\n",
    "    return np.array(majority_images), np.array(majority_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def penobscot_data_seg(patch,stride):\n",
    "    inlines, masks_in=read_files(\"/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/inlines\",'/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/masks')\n",
    "    inlines = ((inlines + 32767) / 65534) * 255\n",
    "    inlines=inlines.astype(np.uint8)\n",
    "    #crosslines, masks_cross=read_files(\"/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/crosslines\",'/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/masks')\n",
    "    patch_inline=divide_into_patches(inlines,patch,stride)\n",
    "    #patch_crossline=divide_into_patches(crosslines,patch,stride)\n",
    "    patch_mask_in=divide_into_patches(masks_in,patch,stride)\n",
    "    #patch_mask_cross=divide_into_patches(masks_cross,patch,stride)\n",
    "\n",
    "    in_train,in_test,in_val=data_split(patch_inline)\n",
    "    mask_in_train,mask_in_test,mask_in_val=data_split(patch_mask_in)\n",
    "\n",
    "    return in_train, mask_in_train, in_test, mask_in_test, in_val, mask_in_val\n",
    "\n",
    "\n",
    "def penobscot_data(patch,stride):\n",
    "    inlines, masks_in=read_files(\"/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/inlines\",'/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/masks')\n",
    "    inlines = ((inlines + 32767) / 65534) * 255\n",
    "    inlines=inlines.astype(np.uint8)\n",
    "    #crosslines, masks_cross=read_files(\"/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/crosslines\",'/home/grad/ccomp/21/nuneslima/Datasets/Penobscot/masks')\n",
    "    patch_inline=divide_into_patches(inlines,patch,stride)\n",
    "    #patch_crossline=divide_into_patches(crosslines,patch,stride)\n",
    "    patch_mask_in=divide_into_patches(masks_in,patch,stride)\n",
    "    #patch_mask_cross=divide_into_patches(masks_cross,patch,stride)\n",
    "\n",
    "    in_train,in_test,in_val=data_split(patch_inline)\n",
    "    mask_in_train,mask_in_test,mask_in_val=data_split(patch_mask_in)\n",
    "    # cross_train,cross_test,cross_val=data_split(patch_crossline)\n",
    "    # mask_cross_train,mask_cross_test,mask_cross_val=data_split(patch_mask_cross)\n",
    "\n",
    "    # trainX=np.append(in_train,cross_train, axis=0)\n",
    "    # trainY=np.append(mask_in_train,mask_cross_train, axis=0)\n",
    "    # testX=np.append(in_test,cross_test, axis=0)\n",
    "    # testY=np.append(mask_in_test,mask_cross_test, axis=0)\n",
    "    # valX=np.append(in_val,cross_val, axis=0)\n",
    "    # valY=np.append(mask_in_val,mask_cross_val, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    patch_train,train_labels = majority_class(in_train, mask_in_train, 0.7)\n",
    "    patch_test,test_labels = majority_class(in_test, mask_in_test, 0.7)\n",
    "    patch_val,val_labels = majority_class(in_val, mask_in_val, 0.7)\n",
    "\n",
    "\n",
    "    return patch_train, train_labels, patch_test, test_labels, patch_val, val_labels\n",
    "\n",
    "    #return trainX, majority_class(trainY), testX, majority_class(testY), valX, majority_class(valY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,trainY,testX,testY,valX,valY=penobscot_data(patch,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)\n",
    "print(valX.shape)\n",
    "print(valY.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismic_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
